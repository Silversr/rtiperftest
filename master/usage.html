<!DOCTYPE HTML><html><head><title>RTI RTI Perftest &mdash; Usage</title><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="generator" content="https://github.com/kevinrenskers/raml2html 3.0.0"><link rel="stylesheet" href="css/bootstrap.min.css"><link rel="stylesheet" href="css/default.min.css"><script type="text/javascript" src="js/jquery-1.11.0.min.js"></script><script type="text/javascript" src="js/bootstrap.min.js"></script><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript">
  function getHost() {
    hostname = window.location.host;
    if(hostname == "") {
      hostname = "localhost:8080";
    }
    return hostname;
  }

  $(document).ready(function() {
    $('.page-header pre code, .top-resource-description pre code').each(function(i, block) {
      hljs.highlightBlock(block);
    });

    $('[data-toggle]').click(function() {
      var selector = $(this).data('target') + ' pre code';
      $(selector).each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });

    // open modal on hashes like #_action_get
    $(window).bind('hashchange', function(e) {
      var anchor_id = document.location.hash.substr(1); //strip #
      var element = $('#' + anchor_id);

      // do we have such element + is it a modal?  --> show it
      if (element.length && element.hasClass('modal')) {
        element.modal('show');
      }
    });

    // execute hashchange on first page load
    $(window).trigger('hashchange');

    // remove url fragment on modal hide
    $('.modal').on('hidden.bs.modal', function() {
      if(history && history.replaceState) {
        history.replaceState({}, '', '#');
      }
    });
    document.body.innerHTML = document.body.innerHTML.replace(
      /##HOST##/g,
      getHost());
  });
  </script><style>
  .hljs {
    background: transparent;
  }
  .parent {
    color: #999;
  }
  .list-group-item > .badge {
    float: none;
    margin-right: 6px;
  }
  .panel-title > .methods {
    float: right;
  }
  .badge {
    border-radius: 0;
    text-transform: uppercase;
    width: 70px;
    font-weight: normal;
    color: #f3f3f6;
    line-height: normal;
  }
  .badge_get {
    background-color: #63a8e2;
  }
  .badge_post {
    background-color: #6cbd7d;
  }
  .badge_put {
    background-color: #22bac4;
  }
  .badge_delete {
    background-color: #d26460;
  }
  .list-group, .panel-group {
    margin-bottom: 0;
  }
  .panel-group .panel+.panel-white {
    margin-top: 0;
  }
  .panel-group .panel-white {
    border-bottom: 1px solid #F5F5F5;
    border-radius: 0;
  }
  .panel-white:last-child {
    border-bottom-color: white;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
  .panel-white .panel-heading {
    background: white;
  }
  .tab-pane ul {
    padding-left: 2em;
  }
  .tab-pane h2 {
    font-size: 1.2em;
    padding-bottom: 4px;
    border-bottom: 1px solid #ddd;
  }
  .tab-pane h3 {
    font-size: 1.1em;
  }
  .tab-content {
    border-left: 1px solid #ddd;
    border-right: 1px solid #ddd;
    border-bottom: 1px solid #ddd;
    padding: 10px;
  }
  #sidebar {
    margin-top: 30px;
  }
  .top-resource-description {
    border-bottom: 1px solid #ddd;
    background: #fcfcfc;
    padding: 15px 15px 0 15px;
    margin: -15px -15px 10px -15px;
  }
  .resource-description {
    border-bottom: 1px solid #fcfcfc;
    background: #fcfcfc;
    padding: 15px 15px 0 15px;
    margin: -15px -15px 10px -15px;
  }
  .list-group .badge {
    float: left;
  }
  .method_description {
    margin-left: 85px;
  }
  .method_description p:last-child {
    margin: 0;
  }
  .list-group-item {
    cursor: pointer;
  }
  .list-group-item:hover {
    background-color: #f5f5f5;
  }
  body { margin-top: 60px; }
  h3:before {
    display: block;
    content: " ";
    margin-top: -60px;
    height: 60px;
    visibility: hidden;
  }
  </style></head><body data-spy="scroll" data-target="#sidebar"><nav class="navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="container"><button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button> <a class="navbar-brand" href="index.html"><img src="img/rti_logo.png" style="vertical-align:bottom" alt="Real-Time Innovations"> <span>&nbsp;RTI Perftest</span></a><div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1"><ul class="nav navbar-nav navbar-right"><li><a href="https://github.com/rticommunity/rtiperftest">GitHub</a></li><li><a href="installation.html">Download</a></li><li><a href="configuration.html">Compilation</a></li><li><a href="usage.html">Parameters</a></li><li><a href="examples.html">Examples</a></li><li><a href="release_notes.html">Release Notes</a></li></ul></div></div></nav><div class="container"><div class="row"><div class="col-md-9" role="main"><div class="page-header"><h1>Usage</h1></div><div class="page-header"><h3 id="1-Use-Examples"><a href="#1-Use-Examples">1 Use Examples</a></h3><p>ameters rameters are available; you can enter them on the command line. ters are optional and case-insensitive; partial matches are allowed (such as <code>-h</code> instead of <code>-help</code>).</p><p>eters only make sense in the publishing or subscribing application. The parameters are presented in the following tables, based on whether they may be used in a publishing application, a subscribing application, or both:</p><p>t Parameters for Publishing and Subscribing Applications](#params-pub-sub) t Parameters Only for Publishing Applications](#params-pub) t Parameters Only for Subscribing Applications](#params-sub) t Parameters to Control RTI Secure DDS Options](#params-pub-sub-secure)</p><p>l see in the tables, the <code>-pub</code> parameter specifies a publishing application and the <code>-sub</code> specifies a subscribing application. If you do not specify See <code>-pub</code> then <code>-sub</code> is assumed.</p><p>onal information on setting the parameters, see sections:</p><p>g vs. Sleeping](#sleepVsSpin) eue Size and Queue-Full Behavior](#queueSize) of Iterations vs. Latency Count](#iterationsVsLatencyCount) Up](#warmUp) Event Count and Delay](#WaitSetEventCount) Measure Latency for a Given Throughput](#lat) ning and Turbo Mode](#AutoTuningTurboMode)</p><p>rameters for Publishing and Subscribing Applications <a id="params-pub-sub"></a></p><p>Effort`</p><p>st-effort communication.</p><p>ult:** <code>false</code> (use reliable communication).</p><p>introduction to the RTI reliability model, see the Strict Reliability design pattern in the RTI Connext DDS Core Libraries Getting Started Guide. See also: Reliable Communications in the RTI Connext DDS Core Libraries User’s Manual.</p><p>Len<bytes>`</bytes></p><p>of payload in bytes for each send.</p><p>ult:<strong><code>100 bytes.</code><br>e:</strong> <code>28 - 63000 bytes</code></p><p>wer limit is the number of "overhead" bytes in the message (i.e., the timestamp, sequence number, and other meta-data used by the test); the upper limit ensures that, when the overhead of the wire protocol is added, it doesn&#39;t overflow the UDP maximum datagram size of 64KB.</p><p><code>-scan</code> is specified, this value is ignored.</p><p>g`</p><p>debug mode (generates more verbose logging messages, which are useful to RTI support personnel).</p><p>ult:** false</p><p>bility<0|1|2|3>`</0|1|2|3></p><p>he Durability kind:</p><p><code>VOLATILE</code> (default)<br><code>TRANSIENT LOCAL</code><br><code>TRANSIENT</code><br><code>PERSISTENT</code></p><p>introduction to the RTI durability model, see the Historical Data design pattern in the RTI Connext DDS Core Libraries Getting Started Guide. See also: Mechanisms for Achieving Information Durability and Persistence, Chapter 12, in the RTI Connext DDS Core Libraries User’s Manual.</p><p>in<id>`</id></p><p>ID.</p><p>blisher and subscriber applications must use the same domain ID in order to communicate.</p><p>ult:<strong><code>1</code><br>e:</strong> <code>0 - 200</code></p><p>oosing a Domain ID and Creating Multiple Domains, Section 8.3.4, in the RTI Connext DDS Core Libraries User’s Manual.</p><p>leSharedMemory`</p><p>the shared memory transport.</p><p>ult:** shared memory transport is disabled</p><p>leTcpOnly`</p><p>e all the other transports and use only TCP transport for communication.</p><p>ult:** TCP transport not enabled</p><p>`</p><p>an informative message with all the available command-line parameters and exit.</p><p>anceHashBuckets<n>`</n></p><p>of hash buckets for instances.</p><p>ult:<strong><code>-1</code> (means same as the number of instances)<br>e:</strong> <code>&gt; 0</code></p><p>ances<int>`</int></p><p>e number of instances to use in the test. The publishing and subscribing applications must specify the same number of instances.</p><p>ption only makes sense when testing a keyed data type; to do so, use See <code>-keyed</code>.</p><p>ult:<strong><code>1</code><br>e:</strong> <code>&gt; 0</code></p><p>DurationUsec<usec>`</usec></p><p>m duration that a sample is queued for ACK-disabled readers. Only used if See <code>-noPositiveAcks</code> is specified on the publisher side.</p><p>sabling Positive Acknowledgements, Section 6.5.3.3 in the RTI Connext DDS Core Libraries User’s Manual.</p><p>ult:<strong><code>1000 µsec</code> (1 millisec).<br>e:</strong> <code>&gt;= 0</code>.</p><p>d`</p><p>y the use of a keyed type.</p><p>ult:** <code>Unkeyed</code> type.</p><p>icast`</p><p>lticast to receive data.</p><p>ult:** do not use multicast.</p><p>icastAddress<address>`</address></p><p>y the multicast receive address for receiving user data.</p><p>pecified, the following default values will be used according to the topic:</p><p>ncy:<strong><code>239.255.1.2</code><br>ughput:</strong> <code>239.255.1.1</code><br>uncement:** <code>239.255.1.100</code></p><p><ipaddr>`</ipaddr></p><p>ct RTI Connext DDS to sending output through this interface. This can be the IP address of any available network interface on the machine.</p><p>ault, RTI Connext DDS will attempt to contact all possible subscribing nodes on all available network interfaces. Even on a multi-NIC machine, the performance over one NIC vs. another may be different (e.g., Gbit vs. 100 Mbit), so choosing the correct NIC is critical for a proper test.</p><p>rectCommunication`</p><p>tes if the subscribing application will receive samples from the publishing application when RTI Persistence Service is used.</p><p>pplies when <code>-durability &lt;0|1|2|3&gt;</code> is <code>TRANSIENT (2)</code> or <code>PERSISTENT (3)</code>.</p><p>to <code>true</code> (the default), the subscribing application gets samples from the publishing application and <em>RTI Persistence Service</em>. This mode provides low latency between endpoints.</p><p>to <code>false</code>, the subscribing application only gets samples from <em>RTI Persistence Service</em>. This brokered communication pattern provides a way to guarantee eventual consistency.</p><p>ult:** <code>true</code> (direct communication)</p><p>lticast`</p><p>use multicast.</p><p>:** Starting in 5.1.0, this option is no longer needed since multicast is disabled by default. It exists only to maintain backward compatibility.</p><p>ult:** Do not use multicast</p><p>sitiveAcks`</p><p>e use of positive ACKs in the reliable protocol.</p><p>ult:** <code>true</code> (use positive ACKs)</p><p>qosprofile<filename>` option for more information.</filename></p><p>intIntervals`</p><p>t printing of statistics at intervals during the test.</p><p>ault, statistics are printed every second in the subscribing application, and after receiving every latency echo in the publishing application.</p><p>rofile<filename>`</filename></p><p>o the XML file containing DDS QoS profiles.</p><p>ult:** <code>perftest_qos_profiles.xml</code></p><p>fault file contains these QoS profiles:<br>hroughputQos<code>,</code>LatencyQos<code>, and</code>AnnouncementQos<code>profiles are used by default.  
oAckThroughputQos</code> and <code>NoAckLatencyQos</code> profiles are used if you specify <code>-noPositiveAcks</code>.</p><p>:** some QoS values are ‘hard-coded’ in the application, therefore setting them in the XML file has no effect; see the See Note:.</p><p>mments in <code>perftest_qos_profiles.xml</code>, as well as <strong>Configuring QoS with XML, Chapter 17</strong> in the <em>RTI Connext DDS Core Libraries</em> User’s Manual.</p><p>eadThread`</p><p>separate thread (instead of a callback) to read data.</p><p>e WaitSet Event Count and Delay</p><p>ult:** use callback for subscriber setDelayUsec<usec>`</usec></p><p>s incoming data in groups, based on time, rather than individually.</p><p>sed if the See <code>-useReadThread</code> option is specified on the subscriber side.</p><p>itSet Event Count and Delay.</p><p>ult:<strong><code>100</code><br>e:</strong> <code>&gt;= 0</code></p><p>setEventCount<count>`</count></p><p>s incoming data in groups, based on the number of samples, rather than individually.</p><p>sed if the See <code>-useReadThread</code> option is specified on the subscriber side.</p><p>e WaitSet Event Count and Delay.</p><p>ult:<strong><code>5</code> e:</strong> <code>&gt;= 1</code></p><p>rameters Only for Publishing Applications <a id="params-pub"></a></p><p>ize<bytes>`</bytes></p><p>batching and set the maximum batched message size.</p><p>ult:<strong><code>0</code> (batching disabled)<br>e:</strong> <code>1 to 63000</code></p><p>re information on batching data for high throughput, see the <strong>High Throughput design pattern</strong> in the <em>RTI Connext DDS Core Libraries Getting Started Guide</em>. See also: <strong>How to Measure Latency for a Given Throughput and the BATCH QosPolicy, Section 6.5.2</strong> in the <em>RTI Connext DDS Core Libraries Getting User’s Manual</em>.</p><p>leAutoThrottle`</p><p>the Auto Throttling feature. See Auto Tuning and Turbo Mode.</p><p>ult:** feature is disabled.</p><p>leTurboMode`</p><p>s the Turbo Mode feature. See See Auto Tuning and Turbo Mode. When turbo mode is enabled, See <code>-batchSize &lt;bytes&gt;</code> is ignored.</p><p>ult:** feature is disabled.</p><p>utionTime<sec>`</sec></p><p>you to limit the test duration by specifying the number of seconds to run the test.</p><p>ult:** feature is not set.</p><p>tbeatPeriod<sec>:<nanosec>`</nanosec></sec></p><p>riod at which the publishing application will send heartbeats.</p><p>Reliable Communications, Chapter 10<em>*, in the</em>RTI Connext DDS Core Libraries Getting User’s Manual*.</p><p>ult:** <code>heartbeat period sec = 0</code>, <code>heartbeat period nanosec = 0</code> (meaning use the value as specified in the XML QoS Profile, which is set to (10 millisec = 10000000 nanosec)).</p><p>qosprofile<filename>`.</filename></p><p>e:** 1 nanosec to 1 year (31,536,000 sec.)</p><p>HeartbeatPeriod<sec>:<nanosec>`</nanosec></sec></p><p>ernative heartbeat period used when the publishing application needs to flush unacknowledged samples more quickly.</p><p>Reliable Communications, Chapter 10<em>*, in the</em>RTI Connext DDS Core Libraries Getting User’s Manual*.</p><p>ult:** <code>heartbeat period sec = 0</code>, <code>heartbeat period nanosec = 0</code> (meaning use the value as specified in the XML QoS Profile, which is set to (1 millisec = 1000000 nanosec)). See</p><p>qosprofile<filename>`.</filename></p><p>e:** (actual value) <code>1 nanosec</code> to <code>1 year (31,536,000 sec)</code>. Must not be slower than See <code>-heartbeatPeriod &lt;sec&gt;:&lt;nanosec&gt;</code>.</p><p>ncyCount<count>`</count></p><p>samples to send before a latency ping packet is sent.</p><p>mber of Iterations vs. Latency Count.</p><p>ult:** <code>-1</code> (if <code>-latencyTest</code> is not specified, automatically adjust to 10000; if -latency Test is specified, automatically adjust to 1).</p><p>e:** must be <code>&lt;= -numIter</code></p><p>ncyTest`</p><p>latency test consisting of a ping-pong.</p><p>blisher sends a ping, then blocks until it receives a pong from the subscriber.</p><p>ly be used on a publisher whose <code>pidMultiPubTest = 0</code> (see See <code>-pidMultiPubTest &lt;id&gt;</code>).</p><p>ult:** <code>false</code> ter<count>`</count></p><p>of samples to send.</p><p>mber of Iterations vs. Latency Count and See Warming Up.</p><p>set <code>scan</code> = <code>true</code>, you cannot set this option (See <code>-scan</code>).</p><p>ult:<strong><code>0</code> (infinite)<br>e:</strong> <code>latencyCount</code> (adjusted value) or higher (see <code>-latencyCount &lt;count&gt;</code>).</p><p>ubscribers<count>`</count></p><p>he publishing application wait for this number of subscribing applications to start.</p><p>ult:** <code>1</code></p><p>ultiPubTest<id>`</id></p><p>e ID of the publisher in a multi-publisher test.</p><p>unique value for each publisher running on the same host that uses the same domain ID.</p><p>ult:<strong><code>0</code><br>e:</strong> <code>0 to n-1</code>, inclusive, where n is the number of publishers in a multi-publisher test.</p><p>st to be a publisher.</p><p>ult:** <code>-sub</code></p><p>ate`</p><p>the throughput to the specified number of samples per second.</p><p>ult:<strong><code>0</code> (no limit)<br>e:</strong> <code>1 to 10000000</code></p><p>`</p><p>st in scan mode, traversing a range of sample data sizes from 32 to 63,000 bytes.</p><p>set <code>scan = true</code>, you cannot set <code>-numIter &lt;count&gt;</code>.</p><p>ult:** <code>false</code> (no scan)</p><p>QueueSize<number>`</number></p><p>f the send queue.</p><p>-batchSize<bytes>` is used, the size is the number of batches.</bytes></p><p>nd-Queue Size and Queue-Full Behavior.</p><p>ult:<strong><code>50</code><br>e:</strong> <code>[1-100 million]</code> or <code>-1</code> (indicating an unlimited length).</p><p>p<millisec>`</millisec></p><p>o sleep between each send.</p><p>inning vs. Sleeping.</p><p>ult:<strong><code>0</code><br>e:</strong> <code>0</code> or higher</p><p><count>`</count></p><p>of times to run in a spin loop between each send.</p><p>inning vs. Sleeping.</p><p>ult:<strong><code>0</code><br>e:</strong> <code>0</code> or higher</p><p>rameters Only for Subscribing Applications <a id="params-sub"></a></p><p>ublishers<count>`</count></p><p>bscribing application will wait for this number of publishing applications to start.</p><p>ult:** <code>1</code></p><p>ultiSubTest<id>`</id></p><p>the subscriber in a multi-subscriber test.</p><p>unique value for each subscriber running on the same host that uses the same domain ID.</p><p>ult:<strong><code>0</code><br>e:</strong> <code>0 to n-1</code>, inclusive, where n is the number of subscribers in a multi-subscriber test.</p><p>st to be a subscriber.</p><p>ult:** <code>-sub</code></p><p>rameters to Control RTI Secure DDS Options (Publishing and Subscribing Applications) <a id="params-pub-sub-secure"></a></p><p>reEncryptDiscovery`</p><p>t discovery traffic.</p><p>ult:** Not set.</p><p>reSign`</p><p>iscovery and user data packages.</p><p>ult:** Not set.</p><p>reEncryptData`</p><p>t at the user data level.</p><p>ult:** Not set.</p><p>reEncryptSM`</p><p>t at the RTPS sub-message level.</p><p>ult:** Not set.</p><p>reGovernanceFile<file>`</file></p><p>ance file. If specified, the authentication, signing, and encryption arguments are ignored. The governance document configuration will be used instead.</p><p>ult:** Not set.</p><p>rePermissionsFile<file>`</file></p><p>sions file to be used.</p><p>ult for Publisher:<strong><code>./resource/secure/signed_PerftestPermissionsPub.xml</code><br>ult for Subscriber:</strong> <code>./resource/secure/signed_PerftestPermissionsSub.xml</code></p><p>reCertAuthority<file>`</file></p><p>icate authority file to be used.</p><p>ult for Publisher:<strong><code>./resource/secure/pub.pem</code><br>ult for Subscriber:</strong> <code>./resource/secure/sub.pem</code></p><p>reCertFile<file>`</file></p><p>icate file to be used.</p><p>ult:** <code>./resource/secure/cacert.pem</code></p><p>rePrivateKey<file>`</file></p><p>e key file to be used.</p><p>ult for Publisher:<strong><code>./resource/secure/pubkey.pem</code> ult for Subscriber:</strong> <code>./resource/secure/subkey.pem</code></p><p>nal information about the parameters</p><p>ng vs. Sleeping <a id="sleepVsSpin"></a></p><p>ublisher is writing as fast as it can, sooner or later, it is likely to get ahead of the subscriber. There are 4 things you can do in this case:</p><p>g -- for reliable communication, <code>write()</code> will block until the subscriber(s) catch up.</p><p>he writing down by sleeping (See <code>-sleep &lt;millisec&gt;</code>). This approach is friendlier to the other processes on the host because it does not monopolize the CPU. However, context switching is expensive enough that you can&#39;t actually "sleep" for amounts of time on the order of microseconds, so you could end up sleeping too long and hurting performance. (Operating systems (including Linux and Windows) have a minimum resolution for sleeping; i.e., you can only sleep for a period of 1 or 10 ms. If you specify a sleep period that is less than that minimum, the OS may sleep for its minimum resolution.)</p><p>n a tight loop between writes (See <code>-spin &lt;count&gt;</code>). This approach will add a pause without giving up the CPU, making it easier to "sleep" for very short periods of time. In the test implementation, there is a very short loop that just performs some simple math to take up CPU time. The argument to <code>-spin &lt;count&gt;</code> (any number &gt;= 0) is the number of times to go through that loop. The default is 0. If you specify something else, it should be a fairly large number (100’s or 1000’s), since spinning the loop just a few times will take negligible time. Avoid spinning on a single-core machine, as the code that would break you out of the spin may not be able to execute in a timely manner.</p><p>e publisher automatically adjust the writing rate (See <code>-enableAutoThrottle</code>). This option enables the Auto Throttle feature introduced in RTI Connext DDS 5.1.0 and its usage is preferred over See <code>-spin &lt;count&gt;</code> because the amount of spin is automatically determined by the publisher based on the number of unacknowledged samples in the send queue.</p><p>Send-Queue Size and Queue-Full Behavior.</p><p>ueue Size and Queue-Full Behavior <a id="queueSize"></a></p><p>stributed systems, a data producer will often outperform data consumers. That means that, if the communications are to be reliable, the producer must be throttled in some way to allow the consumers to keep up. In some situations, this may not be a problem, because data may simply not be ready for publication at a rate sufficient to overwhelm the subscribers. If you&#39;re not so lucky, your publisher&#39;s queue of unacknowledged data will eventually fill up. When that happens, if data is not to be lost, the publication will have to block until space becomes available. Blocking can cost you in terms of latency.</p><p>he cost of blocking, consider the following:</p><p>your publisher&#39;s queue (See <code>-sendQueueSize &lt;number&gt;</code>). Doing so will mean your publisher has to block less often. However, it may also let the publisher get even further ahead of slower subscribers, increasing the number of dropped and resent packets, hurting throughput. Experimenting with the send queue size is one of the easy things you can do to squeeze a little more throughput from your system.</p><p>uto Throttling (See <code>-enableAutoThrottle</code>). This option enables the Auto Throttle feature introduced in <em>RTI Connext DDS 5.1.0</em>. When this option is used, the publisher automatically adjusts the writing rate based on the number of unacknowledged samples in the send queue to avoid blocking.</p><p>ing values in the <code>DataWriterProtocolQosPolicy</code> are ‘hard-coded’ in the application, therefore setting these values in the XML QoS profile will have no effect:</p><p>liable_writer.heartbeats_per_max_samples<code>is set to (</code>sendQueueSize/10<code>)
liable_writer.low_watermark</code> is set to (<code>sendQueueSize * 0.10</code>) liable_writer.high_watermark<code>is set to (</code>sendQueueSize * 0.90`)</p><p>nformation on the send queue size, see the <code>RESOURCE_LIMITS</code> QosPolicy, <strong>Section 6.5.20</strong> in the <em>RTI Connext DDS Core Libraries User’s Manual</em> (specifically, the <code>max_samples</code> field).</p><p>of Iterations vs. Latency Count <a id="iterationsVsLatencyCount"></a></p><p>guring the total number of samples to send during the test (See <code>-numIter &lt;count&gt;</code>) and the number of samples to send between latency pings (See <code>-latencyCount &lt;count&gt;</code>), keep these things in mind:</p><p>nd latency pings too often. One of the purposes of the test is to measure the throughput that the middleware is able to achieve. Although the total throughput is technically the total data sent on both the throughput and latency topics, for the sake of simplicity, the test measures only the former. The implicit assumption is that the latter is negligible by comparison. If you violate this assumption, your throughput test results will not be meaningful.</p><p>number of iterations large enough to send many latency pings over the course of the test run. (That is, keep See <code>-numIter &lt;count&gt;</code> small compared to See <code>-latencyCount &lt;count&gt;</code>). Your latency measurements, and the spread between them, will be of higher quality if you are able to measure more data points.</p><p>ecting See <code>-numIter &lt;count&gt;</code>, choose a value that allows the test to run for at least a minute to get accurate results. Set See <code>-numIter &lt;count&gt;</code> to be millions for small message sizes (&lt;1k); reduce as needed for larger sizes (otherwise the tests will take longer and longer to complete).</p><p>g Up <a id="warmUp"></a></p><p>ng the performance test in <em>Java</em>, and to a lesser extent, <em>C#</em>, you may observe that throughput slowly increases through the first few incremental measurements and then levels off. This improvement reflects the background activity of the just-in-time (JIT) compiler and optimizer on these platforms. For the best indication of steady-state performance, be sure to run the test for a number of samples (See <code>-numIter &lt;count&gt;</code>) sufficient to smooth out this start-up artifact.</p><p>t Event Count and Delay <a id="WaitSetEventCount"></a></p><p>xt DDS<em>, and by extension, this performance test, gives you the option to either process received data in the middleware&#39;s receive thread, via a listener callback, or in a separate thread (See <code>-useReadThread</code>) via an object called a WaitSet. The latter approach can be beneficial in that it decouples the operation of your application from the middleware, so that your processing will not interfere with</em>Connext DDS*&#39;s internal activities. However, it does introduce additional context switches into your data receive path. When data is arriving at a high rate, these context switches can adversely impact performance when they occur with each data sample.</p><p>efficiency, the command line parameters <code>-waitsetDelayUsec &lt;usec&gt;</code> and <code>-waitsetEventCount &lt;count&gt;</code> allow you to process incoming data in groups, based on the number of samples and/or time, rather than individually, reducing the number of context switches. Experiment with these values to optimize performance for your system.</p><p>nformation, see these sections in the <em>RTI Connext DDS Core Libraries User’s Manual</em>: <strong>Receive Threads (Section 19.3)</strong> and <strong>Conditions and WaitSets (Section 4.6)</strong>.</p><p>Measure Latency for a Given Throughput <a id="lat"></a></p><p>t to measure the minimum latency for a given throughput, you have to use the command-line parameters <code>-sleep &lt;millisec&gt;</code>, <code>-spin &lt;count&gt;</code> and <code>-batchSize &lt;bytes&gt;</code> to experimentally set the throughput level for a given test run.</p><p>e, suppose you want to generate a graph of latency vs. throughput for a packet size of <code>200 bytes</code> and throughput rates of <code>1000</code>, <code>10K</code>, <code>20K</code>, <code>50K</code>, <code>100K</code>, <code>500K</code>, and <code>Max messages</code> per second.</p><p>hput rates under 1000 messages per second, use <code>-sleep &lt;ms&gt;</code> to throttle the publishing application. For example, <code>-sleep 1</code> will produce a throughput of approximately 1000 messages/second; <code>-sleep 2</code> will produce a throughput of approximately 500 messages/second.</p><p>hput rates higher than 1000 messages per second, use <code>-spin &lt;spin count&gt;</code> to cause the publishing application to busy wait between sends. The <code>&lt;spin count&gt;</code> value needed to produce a given throughput must be experimentally determined and is highly dependent on processor performance. For example <code>-spin 19000</code> may produce a message rate of 10000 messages/second with a slow processor but a rate of 14000 messages/second with a faster processor.</p><p>ng when you want to measure latency for throughput rates higher than the maximum rates of sending individual messages. First, determine the maximum throughput rate for the data size under test without batching (omit See <code>-batchSize &lt;bytes&gt;</code>). For example, on a 1-Gigabyte network, for a data size of <code>200 bytes</code>, the maximum throughput will be about 70,000 messages/sec. We will refer to this value as <code>max_no_batch</code>.</p><p>roughput rates less than <code>max_no_batch</code> (e.g., 70,000 messages/sec.), do not use batching, as this will increase the latency.</p><p>ng to test for throughput rates higher than <code>max_no_batch</code>: start by setting <code>-batchSize</code> to a multiple of the data size. For example, if the data size is <code>200 bytes</code>, use <code>-batchSize 400</code> (this will put 2 messages in each batch), <code>-batchSize 800</code> (4 per batch), etc. This will allow you to get throughput/latency results for throughputs higher than the <code>max_no_batch</code> throughput rate.</p><p>For larger data sizes (<code>8000 bytes</code> and higher), batching often does not improve throughput, at least for 1-Gigabyte networks.</p><p>uning and Turbo Mode <a id="AutoTuningTurboMode"></a></p><p>xt DDS 5.1.0<em>includes two features that allow the middleware to auto-tune the communications to achieve better performance. These features are <strong>Auto Throttling</strong> and <strong>Turbo Mode</strong>. For more information about both features, refer to <strong>Sections 10.4, Auto Throttling for DataWriter Performance -- Experimental Feature</strong> and <strong>6.5.2.4 Turbo Mode: Automatically Adjusting the Number of Bytes in a Batch -- Experimental</strong> Feature in the</em>RTI Connext DDS Core Libraries User&#39;s Manual*. The performance test application includes two command-line options to enable these features: <code>-enableAutoThrottle</code> and <code>-enableTurboMode</code>.</p><p>Throttling, the publisher automatically adjusts the writing rate based on the number of unacknowledged samples in the send queue to avoid blocking and provide the best latency/throughput tradeoff.</p><p>Mode, the size of a batch is automatically adjusted to provide the best latency for a given write rate. For slow write rates, the batch size will be smaller to minimize the latency penalty. For high write rates, the batch size will be bigger to increase throughput. When turbo mode is used, the command line option See <code>-batchSize &lt;bytes&gt;</code> is ignored.</p><p>the best latency under maximum throughput conditions, use See <code>-enableAutoThrottle</code> and See <code>-enableTurboMode</code> in combination.</p></div></div><div class="col-md-3"><div id="sidebar" class="hidden-print affix" role="complementary"><ul class="nav nav-pills nav-stacked"><li><a href="#1-Use-Examples">1 Use Examples</a></li></ul></div></div></div></div></body></html>