<!DOCTYPE HTML><html><head><title>RTI Perftest &mdash; Command-Line Parameters</title><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><meta name="generator" content="https://github.com/kevinrenskers/raml2html 3.0.0"><link rel="stylesheet" href="css/bootstrap.min.css"><link rel="stylesheet" href="css/default.min.css"><script type="text/javascript" src="js/jquery-1.11.0.min.js"></script><script type="text/javascript" src="js/bootstrap.min.js"></script><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript">
  function getHost() {
    hostname = window.location.host;
    if(hostname == "") {
      hostname = "localhost:8080";
    }
    return hostname;
  }

  $(document).ready(function() {
    $('.page-header pre code, .top-resource-description pre code').each(function(i, block) {
      hljs.highlightBlock(block);
    });

    $('[data-toggle]').click(function() {
      var selector = $(this).data('target') + ' pre code';
      $(selector).each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });

    // open modal on hashes like #_action_get
    $(window).bind('hashchange', function(e) {
      var anchor_id = document.location.hash.substr(1); //strip #
      var element = $('#' + anchor_id);

      // do we have such element + is it a modal?  --> show it
      if (element.length && element.hasClass('modal')) {
        element.modal('show');
      }
    });

    // execute hashchange on first page load
    $(window).trigger('hashchange');

    // remove url fragment on modal hide
    $('.modal').on('hidden.bs.modal', function() {
      if(history && history.replaceState) {
        history.replaceState({}, '', '#');
      }
    });
    document.body.innerHTML = document.body.innerHTML.replace(
      /##HOST##/g,
      getHost());
  });
  </script><style>
  .hljs {
    background: transparent;
  }
  .parent {
    color: #FFFFF;
  }
  .list-group-item > .badge {
    float: none;
    margin-right: 6px;
  }
  .panel-title > .methods {
    float: right;
  }
  .badge {
    border-radius: 0;
    text-transform: uppercase;
    width: 70px;
    font-weight: normal;
    color: #f3f3f6;
    line-height: normal;
  }
  .badge_get {
    background-color: #63a8e2;
  }
  .badge_post {
    background-color: #6cbd7d;
  }
  .badge_put {
    background-color: #22bac4;
  }
  .badge_delete {
    background-color: #d26460;
  }
  .list-group, .panel-group {
    margin-bottom: 0;
  }
  .panel-group .panel+.panel-white {
    margin-top: 0;
  }
  .panel-group .panel-white {
    border-bottom: 1px solid #F5F5F5;
    border-radius: 0;
  }
  .panel-white:last-child {
    border-bottom-color: white;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
  .panel-white .panel-heading {
    background: white;
  }
  .tab-pane ul {
    padding-left: 2em;
  }
  .tab-pane h2 {
    font-size: 1.2em;
    padding-bottom: 4px;
    border-bottom: 1px solid #ddd;
  }
  .tab-pane h3 {
    font-size: 1.1em;
  }
  .tab-content {
    border-left: 1px solid #ddd;
    border-right: 1px solid #ddd;
    border-bottom: 1px solid #ddd;
    padding: 10px;
  }
  #sidebar {
    margin-top: 30px;
  }
  .top-resource-description {
    border-bottom: 1px solid #ddd;
    background: #fcfcfc;
    padding: 15px 15px 0 15px;
    margin: -15px -15px 10px -15px;
  }
  .resource-description {
    border-bottom: 1px solid #fcfcfc;
    background: #fcfcfc;
    padding: 15px 15px 0 15px;
    margin: -15px -15px 10px -15px;
  }
  .list-group .badge {
    float: left;
  }
  .method_description {
    margin-left: 85px;
  }
  .method_description p:last-child {
    margin: 0;
  }
  .list-group-item {
    cursor: pointer;
  }
  .list-group-item:hover {
    background-color: #FFFFF;
  }
  .navbar-inverse {
    background-color: #305590;
    border-color: #305590;
  }
  .navbar-inverse .navbar-nav>li>a {
    color: #f5f5f5;
  }
  .navbar-inverse .navbar-brand {
    color: #f5f5f5;
  }
  .nav-pills>li.active>a, .nav-pills>li.active>a:hover, .nav-pills>li.active>a:focus {
    color: #fff;
    background-color: #305590;
  }
  a {
    color: #305590;
  }
  h1, .h1 {
    color: #ec9900;
  }
  h3, .h3 {
    font-size: 26px;
    margin-bottom: 20px;
  }
  body { margin-top: 60px; }
  h3:before {
    display: block;
    content: " ";
    margin-top: -60px;
    height: 60px;
    visibility: hidden;
  }
  code {
    color: #ce7603;
  }
  h4, .h4, h5, .h5, h6, .h6 {
    margin-top: 20px;
    margin-bottom: 10px;
  }
  </style></head><body data-spy="scroll" data-target="#sidebar"><nav class="navbar navbar-inverse navbar-fixed-top" role="navigation"><div class="container"><button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span></button> <a class="navbar-brand" href="index.html"><img src="img/rti_logo.png" style="vertical-align:bottom" alt="Real-Time Innovations"> <span>&nbsp;&nbsp;RTI Perftest</span></a><div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1"><ul class="nav navbar-nav navbar-right"><li><a href="https://github.com/rticommunity/rtiperftest">GitHub</a></li><li><a href="download.html">Download</a></li><li><a href="compilation.html">Compilation</a></li><li><a href="command_line_parameters.html">Parameters</a></li><li><a href="examples.html">Examples</a></li><li><a href="release_notes.html">Release Notes</a></li></ul></div></div></nav><div class="container"><div class="row"><div class="col-md-9" role="main"><div class="page-header"><h1>Command-Line Parameters</h1></div><div class="page-header"><h3 id="1-Command-Line-Parameters"><a href="#1-Command-Line-Parameters">1 Command-Line Parameters</a></h3><p>Several parameters are available; you can enter them on the command line. All parameters are optional and case-insensitive; partial matches are allowed (such as <code>-h</code> instead of <code>-help</code>).</p><p>Some parameters only make sense in the publishing or subscribing application. The parameters are presented in the following tables, based on whether they may be used in a publishing application, a subscribing application, or both:</p><ul><li>See <a href="#params-pub-sub">Test Parameters for Publishing and Subscribing Applications</a></li><li>See <a href="#params-pub">Test Parameters Only for Publishing Applications</a></li><li>See <a href="#params-sub">Test Parameters Only for Subscribing Applications</a></li><li>See <a href="#params-pub-sub-secure">Test Parameters to Control RTI Secure DDS Options</a></li></ul><p>As you will see in the tables, the <code>-pub</code> parameter specifies a publishing application and the <code>-sub</code> specifies a subscribing application. If you do not specify See <code>-pub</code> then <code>-sub</code> is assumed.</p><p>For additional information on setting the parameters, see sections:</p><ul><li><a href="#sleepVsSpin">Spinning vs. Sleeping</a></li><li><a href="#queueSize">Send-Queue Size and Queue-Full Behavior</a></li><li><a href="#iterationsVsLatencyCount">Number of Iterations vs. Latency Count</a></li><li><a href="#warmUp">Warming Up</a></li><li><a href="#WaitSetEventCount">WaitSet Event Count and Delay</a></li><li><a href="#lat">How to Measure Latency for a Given Throughput</a></li><li><a href="#AutoTuningTurboMode">Auto Tuning and Turbo Mode</a></li></ul><h3 id="test-parameters-for-publishing-and-subscribing-applications-a-id-params-pub-sub-a-">Test Parameters for Publishing and Subscribing Applications <a id="params-pub-sub"></a></h3><ul><li><p><code>-bestEffort</code></p><p>Use best-effort communication.</p><p><strong>Default:</strong> <code>false</code> (use reliable communication).</p><p>For an introduction to the RTI reliability model, see the Strict Reliability design pattern in the RTI Connext DDS Core Libraries Getting Started Guide. See also: Reliable Communications in the RTI Connext DDS Core Libraries User’s Manual.</p></li><li><p><code>-dataLen &lt;bytes&gt;</code></p><p>Length of payload in bytes for each send.</p><p><strong>Default:</strong> <code>100 bytes.</code><br><strong>Range:</strong> <code>28 - 63000 bytes</code></p><p>The lower limit is the number of "overhead" bytes in the message (i.e., the timestamp, sequence number, and other meta-data used by the test); the upper limit ensures that, when the overhead of the wire protocol is added, it doesn&#39;t overflow the UDP maximum datagram size of 64KB.</p><p>If See <code>-scan</code> is specified, this value is ignored.</p></li><li><p><code>-debug</code></p><p>Run in debug mode (generates more verbose logging messages, which are useful to RTI support personnel).</p><p><strong>Default:</strong> false</p></li><li><p><code>-durability &lt;0|1|2|3&gt;</code></p><p>Sets the Durability kind:</p><p><code>0</code> - <code>VOLATILE</code> (default)<br><code>1</code> - <code>TRANSIENT LOCAL</code><br><code>2</code> - <code>TRANSIENT</code><br><code>3</code> - <code>PERSISTENT</code></p><p>For an introduction to the RTI durability model, see the Historical Data design pattern in the RTI Connext DDS Core Libraries Getting Started Guide. See also: Mechanisms for Achieving Information Durability and Persistence, Chapter 12, in the RTI Connext DDS Core Libraries User’s Manual.</p></li><li><p><code>-domain &lt;ID&gt;</code></p><p>Domain ID.</p><p>The publisher and subscriber applications must use the same domain ID in order to communicate.</p><p><strong>Default:</strong> <code>1</code><br><strong>Range:</strong> <code>0 - 200</code></p><p>See Choosing a Domain ID and Creating Multiple Domains, Section 8.3.4, in the RTI Connext DDS Core Libraries User’s Manual.</p></li><li><p><code>-enableSharedMemory</code></p><p>Enable the shared memory transport.</p><p><strong>Default:</strong> shared memory transport is disabled</p></li><li><p><code>-enableTcpOnly</code></p><p>Disable all the other transports and use only TCP transport for communication.</p><p><strong>Default:</strong> TCP transport not enabled</p></li><li><p><code>-help</code></p><p>Print an informative message with all the available command-line parameters and exit.</p></li><li><p><code>-instanceHashBuckets &lt;n&gt;</code></p><p>Number of hash buckets for instances.</p><p><strong>Default:</strong> <code>-1</code> (means same as the number of instances)<br><strong>Range:</strong> <code>&gt; 0</code></p></li><li><p><code>-instances &lt;int&gt;</code></p><p>Set the number of instances to use in the test. The publishing and subscribing applications must specify the same number of instances.</p><p>This option only makes sense when testing a keyed data type; to do so, use See <code>-keyed</code>.</p><p><strong>Default:</strong> <code>1</code><br><strong>Range:</strong> <code>&gt; 0</code></p></li><li><p><code>-keepDurationUsec &lt;usec&gt;</code></p><p>Minimum duration that a sample is queued for ACK-disabled readers. Only used if See <code>-noPositiveAcks</code> is specified on the publisher side.</p><p>See Disabling Positive Acknowledgements, Section 6.5.3.3 in the RTI Connext DDS Core Libraries User’s Manual.</p><p><strong>Default:</strong> <code>1000 µsec</code> (1 millisec).<br><strong>Range:</strong> <code>&gt;= 0</code>.</p></li><li><p><code>-keyed</code></p><p>Specify the use of a keyed type.</p><p><strong>Default:</strong> <code>Unkeyed</code> type.</p></li><li><p><code>-multicast</code></p><p>Use multicast to receive data.</p><p><strong>Default:</strong> do not use multicast.</p></li><li><p><code>-multicastAddress &lt;address&gt;</code></p><p>Specify the multicast receive address for receiving user data.</p><p>If unspecified, the following default values will be used according to the topic:</p><p><strong>latency:</strong> <code>239.255.1.2</code><br><strong>throughput:</strong> <code>239.255.1.1</code><br><strong>announcement:</strong> <code>239.255.1.100</code></p></li><li><p><code>-nic &lt;ipaddr&gt;</code></p><p>Restrict RTI Connext DDS to sending output through this interface. This can be the IP address of any available network interface on the machine.</p><p>By default, RTI Connext DDS will attempt to contact all possible subscribing nodes on all available network interfaces. Even on a multi-NIC machine, the performance over one NIC vs. another may be different (e.g., Gbit vs. 100 Mbit), so choosing the correct NIC is critical for a proper test.</p></li><li><p><code>-noDirectCommunication</code></p><p>Indicates if the subscribing application will receive samples from the publishing application when RTI Persistence Service is used.</p><p>Only applies when <code>-durability &lt;0|1|2|3&gt;</code> is <code>TRANSIENT (2)</code> or <code>PERSISTENT (3)</code>.</p><p>If set to <code>true</code> (the default), the subscribing application gets samples from the publishing application and <em>RTI Persistence Service</em>. This mode provides low latency between endpoints.</p><p>If set to <code>false</code>, the subscribing application only gets samples from <em>RTI Persistence Service</em>. This brokered communication pattern provides a way to guarantee eventual consistency.</p><p><strong>Default:</strong> <code>true</code> (direct communication)</p></li><li><p><code>-nomulticast</code></p><p>Do not use multicast.</p><p><strong>Note:</strong> Starting in 5.1.0, this option is no longer needed since multicast is disabled by default. It exists only to maintain backward compatibility.</p><p><strong>Default:</strong> Do not use multicast</p></li><li><p><code>-noPositiveAcks</code></p><p>Disable use of positive ACKs in the reliable protocol.</p><p><strong>Default:</strong> <code>true</code> (use positive ACKs)</p><p>See <code>-qosprofile &lt;filename&gt;</code> option for more information.</p></li><li><p><code>-noPrintIntervals</code></p><p>Prevent printing of statistics at intervals during the test.</p><p>By default, statistics are printed every second in the subscribing application, and after receiving every latency echo in the publishing application.</p></li><li><p><code>-qosprofile &lt;filename&gt;</code></p><p>Path to the XML file containing DDS QoS profiles.</p><p><strong>Default:</strong> <code>perftest_qos_profiles.xml</code></p><p>The default file contains these QoS profiles:<br>The <code>ThroughputQos</code>, <code>LatencyQos</code>, and <code>AnnouncementQos</code> profiles are used by default.<br>The <code>NoAckThroughputQos</code> and <code>NoAckLatencyQos</code> profiles are used if you specify <code>-noPositiveAcks</code>.</p><p><strong>Note:</strong> some QoS values are ‘hard-coded’ in the application, therefore setting them in the XML file has no effect; see the See Note:.</p><p>See comments in <code>perftest_qos_profiles.xml</code>, as well as <strong>Configuring QoS with XML, Chapter 17</strong> in the <em>RTI Connext DDS Core Libraries</em> User’s Manual.</p></li><li><p><code>-useReadThread</code></p><p>Use a separate thread (instead of a callback) to read data.</p><p>See See WaitSet Event Count and Delay</p><p><strong>Default:</strong> use callback for subscriber</p></li><li><p><code>-waitsetDelayUsec &lt;usec&gt;</code></p><p>Process incoming data in groups, based on time, rather than individually.</p><p>Only used if the See <code>-useReadThread</code> option is specified on the subscriber side.</p><p>See WaitSet Event Count and Delay.</p><p><strong>Default:</strong> <code>100</code><br><strong>Range:</strong> <code>&gt;= 0</code></p></li><li><p><code>-waitsetEventCount &lt;count&gt;</code></p><p>Process incoming data in groups, based on the number of samples, rather than individually.</p><p>Only used if the See <code>-useReadThread</code> option is specified on the subscriber side.</p><p>See See WaitSet Event Count and Delay.</p><p><strong>Default:</strong> <code>5</code> <strong>Range:</strong> <code>&gt;= 1</code></p></li></ul><h3 id="test-parameters-only-for-publishing-applications-a-id-params-pub-a-">Test Parameters Only for Publishing Applications <a id="params-pub"></a></h3><ul><li><p><code>-batchSize &lt;bytes&gt;</code></p><p>Enable batching and set the maximum batched message size.</p><p><strong>Default:</strong> <code>0</code> (batching disabled)<br><strong>Range:</strong> <code>1 to 63000</code></p><p>For more information on batching data for high throughput, see the <strong>High Throughput design pattern</strong> in the <em>RTI Connext DDS Core Libraries Getting Started Guide</em>. See also: <strong>How to Measure Latency for a Given Throughput and the BATCH QosPolicy, Section 6.5.2</strong> in the <em>RTI Connext DDS Core Libraries Getting User’s Manual</em>.</p></li><li><p><code>-enableAutoThrottle</code></p><p>Enable the Auto Throttling feature. See Auto Tuning and Turbo Mode.</p><p><strong>Default:</strong> feature is disabled.</p></li><li><p><code>-enableTurboMode</code></p><p>Enables the Turbo Mode feature. See See Auto Tuning and Turbo Mode. When turbo mode is enabled, See <code>-batchSize &lt;bytes&gt;</code> is ignored.</p><p><strong>Default:</strong> feature is disabled.</p></li><li><p><code>-executionTime &lt;sec&gt;</code></p><p>Allows you to limit the test duration by specifying the number of seconds to run the test.</p><p><strong>Default:</strong> feature is not set.</p></li><li><p><code>-heartbeatPeriod &lt;sec&gt;:&lt;nanosec&gt;</code></p><p>The period at which the publishing application will send heartbeats.</p><p>See <strong>Reliable Communications, Chapter 10</strong>, in the <em>RTI Connext DDS Core Libraries Getting User’s Manual</em>.</p><p><strong>Default:</strong> <code>heartbeat period sec = 0</code>, <code>heartbeat period nanosec = 0</code> (meaning use the value as specified in the XML QoS Profile, which is set to (10 millisec = 10000000 nanosec)).</p><p>See <code>-qosprofile &lt;filename&gt;</code>.</p><p><strong>Range:</strong> 1 nanosec to 1 year (31,536,000 sec.)</p></li><li><p><code>-fastHeartbeatPeriod &lt;sec&gt;:&lt;nanosec&gt;</code></p><p>An alternative heartbeat period used when the publishing application needs to flush unacknowledged samples more quickly.</p><p>See <strong>Reliable Communications, Chapter 10</strong>, in the <em>RTI Connext DDS Core Libraries Getting User’s Manual</em>.</p><p><strong>Default:</strong> <code>heartbeat period sec = 0</code>, <code>heartbeat period nanosec = 0</code> (meaning use the value as specified in the XML QoS Profile, which is set to (1 millisec = 1000000 nanosec)). See</p><p>See <code>-qosprofile &lt;filename&gt;</code>.</p><p><strong>Range:</strong> (actual value) <code>1 nanosec</code> to <code>1 year (31,536,000 sec)</code>. Must not be slower than See <code>-heartbeatPeriod &lt;sec&gt;:&lt;nanosec&gt;</code>.</p></li><li><p><code>-latencyCount &lt;count&gt;</code></p><p>Number samples to send before a latency ping packet is sent.</p><p>See Number of Iterations vs. Latency Count.</p><p><strong>Default:</strong> <code>-1</code> (if <code>-latencyTest</code> is not specified, automatically adjust to 10000; if -latency Test is specified, automatically adjust to 1).</p><p><strong>Range:</strong> must be <code>&lt;= -numIter</code></p></li><li><p><code>-latencyTest</code></p><p>Run a latency test consisting of a ping-pong.</p><p>The publisher sends a ping, then blocks until it receives a pong from the subscriber.</p><p>Can only be used on a publisher whose <code>pidMultiPubTest = 0</code> (see See <code>-pidMultiPubTest &lt;id&gt;</code>).</p><p><strong>Default:</strong> <code>false</code></p></li><li><p><code>-numIter &lt;count&gt;</code></p><p>Number of samples to send.</p><p>See Number of Iterations vs. Latency Count and See Warming Up.</p><p>If you set <code>scan</code> = <code>true</code>, you cannot set this option (See <code>-scan</code>).</p><p><strong>Default:</strong> <code>0</code> (infinite)<br><strong>Range:</strong> <code>latencyCount</code> (adjusted value) or higher (see <code>-latencyCount &lt;count&gt;</code>).</p></li><li><p><code>-numSubscribers &lt;count&gt;</code></p><p>Have the publishing application wait for this number of subscribing applications to start.</p><p><strong>Default:</strong> <code>1</code></p></li><li><p><code>-pidMultiPubTest &lt;id&gt;</code></p><p>Set the ID of the publisher in a multi-publisher test.</p><p>Use a unique value for each publisher running on the same host that uses the same domain ID.</p><p><strong>Default:</strong> <code>0</code><br><strong>Range:</strong> <code>0 to n-1</code>, inclusive, where n is the number of publishers in a multi-publisher test.</p></li><li><p><code>-pub</code></p><p>Set test to be a publisher.</p><p><strong>Default:</strong> <code>-sub</code></p></li><li><p><code>-pubRate</code></p><p>Limit the throughput to the specified number of samples per second.</p><p><strong>Default:</strong> <code>0</code> (no limit)<br><strong>Range:</strong> <code>1 to 10000000</code></p></li><li><p><code>-scan</code></p><p>Run test in scan mode, traversing a range of sample data sizes from 32 to 63,000 bytes.</p><p>If you set <code>scan = true</code>, you cannot set <code>-numIter &lt;count&gt;</code>.</p><p><strong>Default:</strong> <code>false</code> (no scan)</p></li><li><p><code>-sendQueueSize &lt;number&gt;</code></p><p>Size of the send queue.</p><p>When <code>-batchSize &lt;bytes&gt;</code> is used, the size is the number of batches.</p><p>See Send-Queue Size and Queue-Full Behavior.</p><p><strong>Default:</strong> <code>50</code><br><strong>Range:</strong> <code>[1-100 million]</code> or <code>-1</code> (indicating an unlimited length).</p></li><li><p><code>-sleep &lt;millisec&gt;</code></p><p>Time to sleep between each send.</p><p>See Spinning vs. Sleeping.</p><p><strong>Default:</strong> <code>0</code><br><strong>Range:</strong> <code>0</code> or higher</p></li><li><p><code>-spin &lt;count&gt;</code></p><p>Number of times to run in a spin loop between each send.</p><p>See Spinning vs. Sleeping.</p><p><strong>Default:</strong> <code>0</code><br><strong>Range:</strong> <code>0</code> or higher</p></li></ul><h3 id="test-parameters-only-for-subscribing-applications-a-id-params-sub-a-">Test Parameters Only for Subscribing Applications <a id="params-sub"></a></h3><ul><li><p><code>-numPublishers &lt;count&gt;</code></p><p>The subscribing application will wait for this number of publishing applications to start.</p><p><strong>Default:</strong> <code>1</code></p></li><li><p><code>-sidMultiSubTest &lt;id&gt;</code></p><p>ID of the subscriber in a multi-subscriber test.</p><p>Use a unique value for each subscriber running on the same host that uses the same domain ID.</p><p><strong>Default:</strong> <code>0</code><br><strong>Range:</strong> <code>0 to n-1</code>, inclusive, where n is the number of subscribers in a multi-subscriber test.</p></li><li><p><code>-sub</code></p><p>Set test to be a subscriber.</p><p><strong>Default:</strong> <code>-sub</code></p></li></ul><h3 id="test-parameters-to-control-rti-secure-dds-options-publishing-and-subscribing-applications-a-id-params-pub-sub-secure-a-">Test Parameters to Control RTI Secure DDS Options (Publishing and Subscribing Applications) <a id="params-pub-sub-secure"></a></h3><ul><li><p><code>-secureEncryptDiscovery</code></p><p>Encrypt discovery traffic.</p><p><strong>Default:</strong> Not set.</p></li><li><p><code>-secureSign</code></p><p>Sign discovery and user data packages.</p><p><strong>Default:</strong> Not set.</p></li><li><p><code>-secureEncryptData</code></p><p>Encrypt at the user data level.</p><p><strong>Default:</strong> Not set.</p></li><li><p><code>-secureEncryptSM</code></p><p>Encrypt at the RTPS sub-message level.</p><p><strong>Default:</strong> Not set.</p></li><li><p><code>-secureGovernanceFile &lt;file&gt;</code></p><p>Governance file. If specified, the authentication, signing, and encryption arguments are ignored. The governance document configuration will be used instead.</p><p><strong>Default:</strong> Not set.</p></li><li><p><code>-securePermissionsFile &lt;file&gt;</code></p><p>Permissions file to be used.</p><p><strong>Default for Publisher:</strong> <code>./resource/secure/signed_PerftestPermissionsPub.xml</code><br><strong>Default for Subscriber:</strong> <code>./resource/secure/signed_PerftestPermissionsSub.xml</code></p></li><li><p><code>-secureCertAuthority &lt;file&gt;</code></p><p>Certificate authority file to be used.</p><p><strong>Default for Publisher:</strong> <code>./resource/secure/pub.pem</code><br><strong>Default for Subscriber:</strong> <code>./resource/secure/sub.pem</code></p></li><li><p><code>-secureCertFile &lt;file&gt;</code></p><p>Certificate file to be used.</p><p><strong>Default:</strong> <code>./resource/secure/cacert.pem</code></p></li><li><p><code>-securePrivateKey &lt;file&gt;</code></p><p>Private key file to be used.</p><p><strong>Default for Publisher:</strong> <code>./resource/secure/pubkey.pem</code> <strong>Default for Subscriber:</strong> <code>./resource/secure/subkey.pem</code></p></li></ul><h3 id="additional-information-about-the-parameters">Additional information about the parameters</h3><h4 id="spinning-vs-sleeping-a-id-sleepvsspin-a-">Spinning vs. Sleeping <a id="sleepVsSpin"></a></h4><p>When the publisher is writing as fast as it can, sooner or later, it is likely to get ahead of the subscriber. There are 4 things you can do in this case:</p><ol><li><p>Nothing -- for reliable communication, <code>write()</code> will block until the subscriber(s) catch up.</p></li><li><p>Slow the writing down by sleeping (See <code>-sleep &lt;millisec&gt;</code>). This approach is friendlier to the other processes on the host because it does not monopolize the CPU. However, context switching is expensive enough that you can&#39;t actually "sleep" for amounts of time on the order of microseconds, so you could end up sleeping too long and hurting performance. (Operating systems (including Linux and Windows) have a minimum resolution for sleeping; i.e., you can only sleep for a period of 1 or 10 ms. If you specify a sleep period that is less than that minimum, the OS may sleep for its minimum resolution.)</p></li><li><p>Spin in a tight loop between writes (See <code>-spin &lt;count&gt;</code>). This approach will add a pause without giving up the CPU, making it easier to "sleep" for very short periods of time. In the test implementation, there is a very short loop that just performs some simple math to take up CPU time. The argument to <code>-spin &lt;count&gt;</code> (any number &gt;= 0) is the number of times to go through that loop. The default is 0. If you specify something else, it should be a fairly large number (100’s or 1000’s), since spinning the loop just a few times will take negligible time. Avoid spinning on a single-core machine, as the code that would break you out of the spin may not be able to execute in a timely manner.</p></li><li><p>Let the publisher automatically adjust the writing rate (See <code>-enableAutoThrottle</code>). This option enables the Auto Throttle feature introduced in RTI Connext DDS 5.1.0 and its usage is preferred over See <code>-spin &lt;count&gt;</code> because the amount of spin is automatically determined by the publisher based on the number of unacknowledged samples in the send queue.</p></li></ol><p>See also: Send-Queue Size and Queue-Full Behavior.</p><h4 id="send-queue-size-and-queue-full-behavior-a-id-queuesize-a-">Send-Queue Size and Queue-Full Behavior <a id="queueSize"></a></h4><p>In many distributed systems, a data producer will often outperform data consumers. That means that, if the communications are to be reliable, the producer must be throttled in some way to allow the consumers to keep up. In some situations, this may not be a problem, because data may simply not be ready for publication at a rate sufficient to overwhelm the subscribers. If you&#39;re not so lucky, your publisher&#39;s queue of unacknowledged data will eventually fill up. When that happens, if data is not to be lost, the publication will have to block until space becomes available. Blocking can cost you in terms of latency.</p><p>To avoid the cost of blocking, consider the following:</p><ul><li><p>Enlarge your publisher&#39;s queue (See <code>-sendQueueSize &lt;number&gt;</code>). Doing so will mean your publisher has to block less often. However, it may also let the publisher get even further ahead of slower subscribers, increasing the number of dropped and resent packets, hurting throughput. Experimenting with the send queue size is one of the easy things you can do to squeeze a little more throughput from your system.</p></li><li><p>Enable Auto Throttling (See <code>-enableAutoThrottle</code>). This option enables the Auto Throttle feature introduced in <em>RTI Connext DDS 5.1.0</em>. When this option is used, the publisher automatically adjusts the writing rate based on the number of unacknowledged samples in the send queue to avoid blocking.</p></li></ul><p><strong>Note:</strong></p><p>The following values in the <code>DataWriterProtocolQosPolicy</code> are ‘hard-coded’ in the application, therefore setting these values in the XML QoS profile will have no effect:</p><ul><li><code>rtps_reliable_writer.heartbeats_per_max_samples</code> is set to (<code>sendQueueSize/10</code>)</li><li><code>rtps_reliable_writer.low_watermark</code> is set to (<code>sendQueueSize * 0.10</code>)</li><li><code>rtps_reliable_writer.high_watermark</code> is set to (<code>sendQueueSize * 0.90</code>)</li></ul><p>For more information on the send queue size, see the <code>RESOURCE_LIMITS</code> QosPolicy, <strong>Section 6.5.20</strong> in the <em>RTI Connext DDS Core Libraries User’s Manual</em> (specifically, the <code>max_samples</code> field).</p><h4 id="number-of-iterations-vs-latency-count-a-id-iterationsvslatencycount-a-">Number of Iterations vs. Latency Count <a id="iterationsVsLatencyCount"></a></h4><p>When configuring the total number of samples to send during the test (See <code>-numIter &lt;count&gt;</code>) and the number of samples to send between latency pings (See <code>-latencyCount &lt;count&gt;</code>), keep these things in mind:</p><ul><li><p>Don&#39;t send latency pings too often. One of the purposes of the test is to measure the throughput that the middleware is able to achieve. Although the total throughput is technically the total data sent on both the throughput and latency topics, for the sake of simplicity, the test measures only the former. The implicit assumption is that the latter is negligible by comparison. If you violate this assumption, your throughput test results will not be meaningful.</p></li><li><p>Keep the number of iterations large enough to send many latency pings over the course of the test run. Your latency measurements, and the spread between them, will be of higher quality if you are able to measure more data points.</p></li><li><p>When selecting See <code>-numIter &lt;count&gt;</code>, choose a value that allows the test to run for at least a minute to get accurate results. Set See <code>-numIter &lt;count&gt;</code> to be millions for small message sizes (&lt;1k); reduce as needed for larger sizes (otherwise the tests will take longer and longer to complete).</p></li></ul><h4 id="warming-up-a-id-warmup-a-">Warming Up <a id="warmUp"></a></h4><p>When running the performance test in <em>Java</em>, and to a lesser extent, <em>C#</em>, you may observe that throughput slowly increases through the first few incremental measurements and then levels off. This improvement reflects the background activity of the just-in-time (JIT) compiler and optimizer on these platforms. For the best indication of steady-state performance, be sure to run the test for a number of samples (See <code>-numIter &lt;count&gt;</code>) sufficient to smooth out this start-up artifact.</p><h4 id="waitset-event-count-and-delay-a-id-waitseteventcount-a-">WaitSet Event Count and Delay <a id="WaitSetEventCount"></a></h4><p><em>RTI Connext DDS</em>, and by extension, this performance test, gives you the option to either process received data in the middleware&#39;s receive thread, via a listener callback, or in a separate thread (See <code>-useReadThread</code>) via an object called a WaitSet. The latter approach can be beneficial in that it decouples the operation of your application from the middleware, so that your processing will not interfere with <em>Connext DDS</em>&#39;s internal activities. However, it does introduce additional context switches into your data receive path. When data is arriving at a high rate, these context switches can adversely impact performance when they occur with each data sample.</p><p>To improve efficiency, the command line parameters <code>-waitsetDelayUsec &lt;usec&gt;</code> and <code>-waitsetEventCount &lt;count&gt;</code> allow you to process incoming data in groups, based on the number of samples and/or time, rather than individually, reducing the number of context switches. Experiment with these values to optimize performance for your system.</p><p>For more information, see these sections in the <em>RTI Connext DDS Core Libraries User’s Manual</em>: <strong>Receive Threads (Section 19.3)</strong> and <strong>Conditions and WaitSets (Section 4.6)</strong>.</p><h4 id="how-to-measure-latency-for-a-given-throughput-a-id-lat-a-">How to Measure Latency for a Given Throughput <a id="lat"></a></h4><p>If you want to measure the minimum latency for a given throughput, you have to use the command-line parameters <code>-sleep &lt;millisec&gt;</code>, <code>-spin &lt;count&gt;</code> and <code>-batchSize &lt;bytes&gt;</code> to experimentally set the throughput level for a given test run.</p><p>For example, suppose you want to generate a graph of latency vs. throughput for a packet size of <code>200 bytes</code> and throughput rates of <code>1000</code>, <code>10K</code>, <code>20K</code>, <code>50K</code>, <code>100K</code>, <code>500K</code>, and <code>Max messages</code> per second.</p><p>For throughput rates under 1000 messages per second, use <code>-sleep &lt;ms&gt;</code> to throttle the publishing application. For example, <code>-sleep 1</code> will produce a throughput of approximately 1000 messages/second; <code>-sleep 2</code> will produce a throughput of approximately 500 messages/second.</p><p>For throughput rates higher than 1000 messages per second, use <code>-spin &lt;spin count&gt;</code> to cause the publishing application to busy wait between sends. The <code>&lt;spin count&gt;</code> value needed to produce a given throughput must be experimentally determined and is highly dependent on processor performance. For example <code>-spin 19000</code> may produce a message rate of 10000 messages/second with a slow processor but a rate of 14000 messages/second with a faster processor.</p><p>Use batching when you want to measure latency for throughput rates higher than the maximum rates of sending individual messages. First, determine the maximum throughput rate for the data size under test without batching (omit See <code>-batchSize &lt;bytes&gt;</code>). For example, on a 1-Gigabyte network, for a data size of <code>200 bytes</code>, the maximum throughput will be about 70,000 messages/sec. We will refer to this value as <code>max_no_batch</code>.</p><p>For all throughput rates less than <code>max_no_batch</code> (e.g., 70,000 messages/sec.), do not use batching, as this will increase the latency.</p><p>Use batching to test for throughput rates higher than <code>max_no_batch</code>: start by setting <code>-batchSize</code> to a multiple of the data size. For example, if the data size is <code>200 bytes</code>, use <code>-batchSize 400</code> (this will put 2 messages in each batch), <code>-batchSize 800</code> (4 per batch), etc. This will allow you to get throughput/latency results for throughputs higher than the <code>max_no_batch</code> throughput rate.</p><p><strong>Note:</strong> For larger data sizes (<code>8000 bytes</code> and higher), batching often does not improve throughput, at least for 1-Gigabyte networks.</p><h4 id="auto-tuning-and-turbo-mode-a-id-autotuningturbomode-a-">Auto Tuning and Turbo Mode <a id="AutoTuningTurboMode"></a></h4><p><em>RTI Connext DDS 5.1.0</em> includes two features that allow the middleware to auto-tune the communications to achieve better performance. These features are <strong>Auto Throttling</strong> and <strong>Turbo Mode</strong>. For more information about both features, refer to <strong>Sections 10.4, Auto Throttling for DataWriter Performance -- Experimental Feature</strong> and <strong>6.5.2.4 Turbo Mode: Automatically Adjusting the Number of Bytes in a Batch -- Experimental</strong> Feature in the <em>RTI Connext DDS Core Libraries User&#39;s Manual</em>. The performance test application includes two command-line options to enable these features: <code>-enableAutoThrottle</code> and <code>-enableTurboMode</code>.</p><p>With Auto Throttling, the publisher automatically adjusts the writing rate based on the number of unacknowledged samples in the send queue to avoid blocking and provide the best latency/throughput tradeoff.</p><p>With Turbo Mode, the size of a batch is automatically adjusted to provide the best latency for a given write rate. For slow write rates, the batch size will be smaller to minimize the latency penalty. For high write rates, the batch size will be bigger to increase throughput. When turbo mode is used, the command line option See <code>-batchSize &lt;bytes&gt;</code> is ignored.</p><p>To achieve the best latency under maximum throughput conditions, use See <code>-enableAutoThrottle</code> and See <code>-enableTurboMode</code> in combination.</p></div></div><div class="col-md-3"><div id="sidebar" class="hidden-print affix" role="complementary"><ul class="nav nav-pills nav-stacked"><li><a href="#1-Command-Line-Parameters">1 Command-Line Parameters</a></li></ul></div></div></div></div></body></html>